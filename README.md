# Claude Code -> GPT OSS Fine-tuned Mentoring Model

A comprehensive GPU-based fine-tuning pipeline for creating Claude-style mentoring AI models using GPT-2 architecture with advanced logging and evaluation capabilities.
The goal of this repo is to tune the open source GPT-OSS (20 GB) model using data collected from my Claude Code sessions in order to have a local LLM to run on my 32 GB MacBook Pro 
with hopefully similar capabilities. This will be a work in progress and require frequent fine tuning.
 
## ğŸ“Š Training Results

- **Model**: GPT-2 â†’ Claude Mentor Fine-tuned
- **Loss Reduction**: 4.08 â†’ 3.03 (26% improvement)
- **Training Efficiency**: ~8 seconds on RTX 4090
- **Dataset**: 40 high-quality mentoring conversations
- **Model Quality**: 83% responses rated "Excellent" (â‰¥0.8 quality score)

## ğŸ—ï¸ Architecture

### Components

```
claude-mentoring-finetune/
â”œâ”€â”€ scripts/                    # Fine-tuning scripts
â”‚   â”œâ”€â”€ auto_setup_and_run.py   # Smart training with API handling
â”‚   â”œâ”€â”€ enhanced_gpu_finetune.py # Advanced GPU training
â”‚   â”œâ”€â”€ optimized_gpu_finetune.py # Optimized parameters
â”‚   â””â”€â”€ robust_finetune.py       # Conservative training approach
â”œâ”€â”€ evaluation/                 # Model testing and evaluation
â”‚   â”œâ”€â”€ test_final_model.py      # Comprehensive model evaluation
â”‚   â””â”€â”€ langsmith_evaluation.py # LangSmith integration
â”œâ”€â”€ config/                     # Configuration and environment
â”‚   â”œâ”€â”€ .env.template           # API key template
â”‚   â””â”€â”€ update_api_keys.py      # Configuration utility
â”œâ”€â”€ data/                       # Training data
â”‚   â””â”€â”€ claude_mentoring_dataset.jsonl # Training conversations
â””â”€â”€ models/                     # Trained model outputs
    â””â”€â”€ claude_mentor_final/    # Production model
```

## ğŸ”§ Quick Start

### 1. Environment Setup

```bash
# Clone repository
git clone https://github.com/yourusername/claude-mentoring-finetune.git
cd claude-mentoring-finetune

# Copy environment template
cp config/.env.template .env

# Edit .env with your API keys
nano .env
```

### 2. Install Dependencies

```bash
# Install PyTorch with CUDA support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# Install ML libraries
pip install transformers datasets accelerate wandb langsmith

# Or use requirements.txt
pip install -r requirements.txt
```

### 3. Configure API Keys

```bash
# Interactive configuration
python config/update_api_keys.py --interactive

# Or edit manually
nano .env
```

### 4. Run Training

```bash
# Automatic setup with smart fallbacks
python scripts/auto_setup_and_run.py

# Or optimized GPU training
python scripts/optimized_gpu_finetune.py
```

### 5. Evaluate Model

```bash
# Comprehensive evaluation
python evaluation/test_final_model.py

# LangSmith evaluation (requires API key)
python evaluation/langsmith_evaluation.py
```
